<!DOCTYPE html>
<html lang="en">
<body>
    <h1>Neural Networks from Scratch</h1>
    <p> This repository contains a series of Jupyter notebooks demonstrating the step-by-step implementation of neural networks starting from a basic Perceptron to a sophisticated deep neural network architecture. Each notebook showcases the evolution from a single Perceptron to a flexible deep neural network capable of handling any number of layers and neurons in each layer. </p>
    <h2>Dataset Utilization</h2>
    <p>Throughout each implementation step, the Cats and Dogs dataset has been employed for training and evaluation
        purposes. The notebooks analyze the predictions generated by the neural networks at each stage of development,
        comparing and evaluating their performance in classifying images of cats and dogs.</p>
    <h2>Core Components Covered</h2>
    <p>The notebooks encompass the comprehensive implementation of:</p>
    <ul>
        <li><strong>Hyperparameters:</strong> Configured and fine-tuned to optimize network performance.</li>
        <li><strong>Activation Functions (Sigmoid):</strong> Employed to introduce non-linearity and improve the network's
            learning capabilities.</li>
        <li><strong>Forward Propagation:</strong> Computation of outputs across various network layers.</li>
        <li><strong>Backpropagation:</strong> Derivation of gradients for parameter updates.</li>
        <li><strong>Hyperparameter Updates:</strong> Utilization of gradients to update parameters and enhance network
            learning.</li>
    </ul>
    <h2>Overview</h2>
    <h3>1. Perceptron Implementation</h3>
    <ul>
        <li><strong>File:</strong> <a href = "https://github.com/zak-soussi/DeepNeuralNetwork_fromScratch/blob/main/CatDog_perceptron.ipynb">CatDog_perceptron.ipynb</a></li>
        <li><strong>Description:</strong> This notebook initiates with the implementation of a fully functional Perceptron
            from scratch. It covers the creation of a single-layer network and its ability to learn from features extracted
            from the Cats and Dogs dataset.</li>
    </ul>
    <h3>2. Two-Layer Network Enhancement</h3>
    <ul>
        <li><strong>File:</strong> <a href = "https://github.com/zak-soussi/DeepNeuralNetwork_fromScratch/blob/main/2layer_neural_network_from_scratch.ipynb">2layer_neural_network_from_scratch.ipynb</a></li>
        <li><strong>Description:</strong> Building upon the Perceptron, this notebook extends the architecture to a
            two-layer neural network. The enhancement showcases the incorporation of hidden layers and their role in
            improving the network's ability to classify cats and dogs.</li>
    </ul>
    <h3>3. Flexible Deep Neural Network</h3>
    <ul>
        <li><strong>File:</strong> <a href = "https://github.com/zak-soussi/DeepNeuralNetwork_fromScratch/blob/main/Deep_neural_network_from_scratch.ipynb">Deep_neural_network_from_scratch.ipynb</a></li>
        <li><strong>Description:</strong> The final notebook demonstrates the development of a customizable deep neural
            network architecture capable of handling multiple layers and varying neuron counts in each layer. It includes
            comprehensive implementations of forward propagation, diverse gradient calculation methods, backpropagation,
            and iterative hyperparameter updates.</li>
    </ul>
    
</body>

</html>
